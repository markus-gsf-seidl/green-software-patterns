"use strict";(self.webpackChunkgsf_docusaurus_template=self.webpackChunkgsf_docusaurus_template||[]).push([[6934],{4930:e=>{e.exports=JSON.parse('{"label":"serverless","permalink":"/tags/serverless","allTagsPath":"/tags","count":2,"items":[{"id":"catalog/ai/serverless-model-development","title":"Adopt serverless architecture for AI/ML workload processes","description":"Building an ML model takes significant computing resources that need to be optimized for efficient utilization.","permalink":"/catalog/ai/serverless-model-development"},{"id":"catalog/cloud/scale-kubernetes-workloads-based-on-events","title":"Scale Kubernetes workloads based on relevent demand metrics","description":"By default, Kubernetes scales workloads based on CPU and RAM utilization. In practice, however, it\'s difficult to correlate your application\'s demand drivers with CPU and RAM utilization. Scaling your workload based on relevant demand metrics that drive scaling of your applications, such as HTTP requests, queue length, and cloud alerting events can help reduce resource utilization, and therefore also your carbon emissions.","permalink":"/catalog/cloud/scale-kubernetes-workloads-based-on-events"}]}')}}]);